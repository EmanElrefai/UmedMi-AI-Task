{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\emma\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\emma\\anaconda3\\lib\\site-packages (from wordcloud) (7.0.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from wordcloud) (1.18.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\emma\\anaconda3\\lib\\site-packages (from wordcloud) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\emma\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud) (45.2.0.post20200210)\n",
      "Requirement already satisfied: xgboost in c:\\users\\emma\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\emma\\anaconda3\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\emma\\anaconda3\\lib\\site-packages (from xgboost) (1.18.1)\n",
      "Requirement already satisfied: keras in c:\\users\\emma\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\emma\\anaconda3\\lib\\site-packages (from keras) (5.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\emma\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\emma\\anaconda3\\lib\\site-packages (from h5py->keras) (1.14.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\emma\\anaconda3\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (1.31.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\emma\\anaconda3\\lib\\site-packages (from protobuf>=3.9.2->tensorflow) (45.2.0.post20200210)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.20.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\emma\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (1.5.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\emma\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\emma\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "seed = 4353\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = pd.read_csv('True.csv')\n",
    "fake = pd.read_csv('Fake.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############\n",
    "true.sample(5)\n",
    "fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introducing new column in both dataframes\n",
    "\n",
    "true['impression']=1\n",
    "fake['impression']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22160</th>\n",
       "      <td>Trump, Liberal Hypocrisy &amp; Humanity’s Future</td>\n",
       "      <td>21st Century Wire says Here s an epic discussi...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>March 19, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13804</th>\n",
       "      <td>Queensland result leaves Australian PM closer ...</td>\n",
       "      <td>SYDNEY (Reuters) - The loss of a state electio...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 27, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Manhattan U.S. attorney adds to probes of ex-T...</td>\n",
       "      <td>WASHINGTON (Reuters) - The U.S. attorney’s off...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>October 25, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>Prominent Psychiatrist Gives One DAMNING Reas...</td>\n",
       "      <td>Given Donald Trump s disastrous presidential c...</td>\n",
       "      <td>News</td>\n",
       "      <td>February 16, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16039</th>\n",
       "      <td>HEATED! MARIA BARTIROMO Goes At It With John P...</td>\n",
       "      <td>John Podesta is the guardian of the Clintons j...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Jun 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10384</th>\n",
       "      <td>Group ends effort to draft House Speaker Ryan ...</td>\n",
       "      <td>WASHINGTON (Reuters) - A group that wanted to ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>March 11, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13696</th>\n",
       "      <td>Indonesian 'Trump' says has no plans to run fo...</td>\n",
       "      <td>SINGAPORE (Reuters) - Indonesian business tyco...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 28, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>There’s Something Really Creepy About Melania...</td>\n",
       "      <td>Handwriting experts have noticed something ver...</td>\n",
       "      <td>News</td>\n",
       "      <td>May 9, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20544</th>\n",
       "      <td>RELIGION OF PROGRESSIVISM: Meet Obama’s NEW Tr...</td>\n",
       "      <td>The religion of Progressivism is working overt...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 21, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12145</th>\n",
       "      <td>GERMANY’S DEFENSE MINISTER Refuses To Wear Hij...</td>\n",
       "      <td>Germany s defense minister refused to wear a t...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Dec 14, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "22160       Trump, Liberal Hypocrisy & Humanity’s Future   \n",
       "13804  Queensland result leaves Australian PM closer ...   \n",
       "1039   Manhattan U.S. attorney adds to probes of ex-T...   \n",
       "2501    Prominent Psychiatrist Gives One DAMNING Reas...   \n",
       "16039  HEATED! MARIA BARTIROMO Goes At It With John P...   \n",
       "10384  Group ends effort to draft House Speaker Ryan ...   \n",
       "13696  Indonesian 'Trump' says has no plans to run fo...   \n",
       "1549    There’s Something Really Creepy About Melania...   \n",
       "20544  RELIGION OF PROGRESSIVISM: Meet Obama’s NEW Tr...   \n",
       "12145  GERMANY’S DEFENSE MINISTER Refuses To Wear Hij...   \n",
       "\n",
       "                                                    text          subject  \\\n",
       "22160  21st Century Wire says Here s an epic discussi...          US_News   \n",
       "13804  SYDNEY (Reuters) - The loss of a state electio...        worldnews   \n",
       "1039   WASHINGTON (Reuters) - The U.S. attorney’s off...     politicsNews   \n",
       "2501   Given Donald Trump s disastrous presidential c...             News   \n",
       "16039  John Podesta is the guardian of the Clintons j...  Government News   \n",
       "10384  WASHINGTON (Reuters) - A group that wanted to ...     politicsNews   \n",
       "13696  SINGAPORE (Reuters) - Indonesian business tyco...        worldnews   \n",
       "1549   Handwriting experts have noticed something ver...             News   \n",
       "20544  The religion of Progressivism is working overt...        left-news   \n",
       "12145  Germany s defense minister refused to wear a t...         politics   \n",
       "\n",
       "                     date  impression  \n",
       "22160      March 19, 2017           0  \n",
       "13804  November 27, 2017            1  \n",
       "1039    October 25, 2017            1  \n",
       "2501    February 16, 2017           0  \n",
       "16039        Jun 29, 2017           0  \n",
       "10384     March 11, 2016            1  \n",
       "13696  November 28, 2017            1  \n",
       "1549          May 9, 2017           0  \n",
       "20544        May 21, 2016           0  \n",
       "12145        Dec 14, 2016           0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating them using pandas concatenate to form a single dataframe\n",
    "\n",
    "data_raw = pd.concat([true, fake], axis=0)\n",
    "data_raw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining title and text to obtain a single string\n",
    "# dropping title and\n",
    "\n",
    "data_raw['fulltext'] = data_raw.title + ' ' + data_raw.text\n",
    "data_raw.drop(['title','text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting a new dataframe using features fulltext and impression\n",
    "data = data_raw[['fulltext', 'impression']]\n",
    "data = data.reset_index()\n",
    "data.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fulltext      0\n",
       "impression    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contans 44898 rows and 2 columns\n"
     ]
    }
   ],
   "source": [
    "print('The dataset contans {} rows and {} columns'.format(data.shape[0], data.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word extraction from true and fake texts\n",
    "\n",
    "true_text = data[data.impression==1]['fulltext']\n",
    "fake_text = data[data.impression==0]['fulltext']\n",
    "fake_text = fake_text.reset_index().drop(['index'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract major words from true and fake news\n",
    "\n",
    "def wordcloud_words(X_data_full):\n",
    "    \n",
    "    # function for removing punctuations\n",
    "    def remove_punct(X_data_func):\n",
    "        string1 = X_data_func.lower()\n",
    "        translation_table = dict.fromkeys(map(ord, string.punctuation),' ')\n",
    "        string2 = string1.translate(translation_table)\n",
    "        return string2\n",
    "  \n",
    "    X_data_full_clear_punct = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = remove_punct(X_data_full[i])\n",
    "        X_data_full_clear_punct.append(test_data)\n",
    "        \n",
    "        # function to remove stopwords\n",
    "    def remove_stopwords(X_data_func):\n",
    "        pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "        string2 = pattern.sub(' ', X_data_func)\n",
    "        return string2\n",
    "    \n",
    "    X_data_full_clear_stopwords = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = remove_stopwords(X_data_full[i])\n",
    "        X_data_full_clear_stopwords.append(test_data)\n",
    "        \n",
    "    # function for tokenizing\n",
    "    def tokenize_words(X_data_func):\n",
    "        words = nltk.word_tokenize(X_data_func)\n",
    "        return words\n",
    "    \n",
    "    X_data_full_tokenized_words = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = tokenize_words(X_data_full[i])\n",
    "        X_data_full_tokenized_words.append(test_data)\n",
    "        \n",
    "    # function for lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def lemmatize_words(X_data_func):\n",
    "        words = lemmatizer.lemmatize(X_data_func)\n",
    "        return words\n",
    "    \n",
    "    X_data_full_lemmatized_words = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = lemmatize_words(X_data_full[i])\n",
    "        X_data_full_lemmatized_words.append(test_data)\n",
    "        \n",
    "    return X_data_full_lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\emma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\emma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "true_words = wordcloud_words(true_text)\n",
    "fake_words = wordcloud_words(fake_text.fulltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ML Models\n",
    "# Data preparation\n",
    "\n",
    "X_data = data['fulltext']\n",
    "y_data = data.impression\n",
    "X_data = X_data.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve processed words\n",
    "\n",
    "def final(X_data_full):\n",
    "    \n",
    "    # function for removing punctuations\n",
    "    def remove_punct(X_data_func):\n",
    "        string1 = X_data_func.lower()\n",
    "        translation_table = dict.fromkeys(map(ord, string.punctuation),' ')\n",
    "        string2 = string1.translate(translation_table)\n",
    "        return string2\n",
    "    \n",
    "    X_data_full_clear_punct = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = remove_punct(X_data_full[i])\n",
    "        X_data_full_clear_punct.append(test_data)\n",
    "        \n",
    "    # function to remove stopwords\n",
    "    def remove_stopwords(X_data_func):\n",
    "        pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "        string2 = pattern.sub(' ', X_data_func)\n",
    "        return string2\n",
    "    \n",
    "    X_data_full_clear_stopwords = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = remove_stopwords(X_data_full[i])\n",
    "        X_data_full_clear_stopwords.append(test_data)\n",
    "        \n",
    "    # function for tokenizing\n",
    "    def tokenize_words(X_data_func):\n",
    "        words = nltk.word_tokenize(X_data_func)\n",
    "        return words\n",
    "    \n",
    "    X_data_full_tokenized_words = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = tokenize_words(X_data_full[i])\n",
    "        X_data_full_tokenized_words.append(test_data)\n",
    "        \n",
    "    # function for lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def lemmatize_words(X_data_func):\n",
    "        words = lemmatizer.lemmatize(X_data_func)\n",
    "        return words\n",
    "    \n",
    "    X_data_full_lemmatized_words = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = lemmatize_words(X_data_full[i])\n",
    "        X_data_full_lemmatized_words.append(test_data)\n",
    "        \n",
    "    # creating the bag of words model\n",
    "    cv = CountVectorizer(max_features=1000)\n",
    "    X_data_full_vector = cv.fit_transform(X_data_full_lemmatized_words).toarray()\n",
    "    \n",
    "    \n",
    "    tfidf = TfidfTransformer()\n",
    "    X_data_full_tfidf = tfidf.fit_transform(X_data_full_vector).toarray()\n",
    "    \n",
    "    return X_data_full_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the function with parameters\n",
    "\n",
    "\n",
    "data_X = final(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and testing data using train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, y_data, test_size=0.25, random_state= seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random Forest\n",
    "# Instatiation, fitting and prediction\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators= 10, random_state= seed)\n",
    "rfc.fit(X_train, y_train)\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      5849\n",
      "           1       1.00      0.99      0.99      5376\n",
      "\n",
      "    accuracy                           0.99     11225\n",
      "   macro avg       0.99      0.99      0.99     11225\n",
      "weighted avg       0.99      0.99      0.99     11225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
